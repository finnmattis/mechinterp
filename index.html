<!DOCTYPE html>
<meta charset="utf-8" />
<link rel="stylesheet" href="styles.css" />
<script src="https://distill.pub/template.v2.js"></script>
<d-front-matter>
  <script type="text/json">
    {
      "title": "Headline",
      "description": "Description",
      "published": "April 14, 2025",
      "authors": [
        {
          "author": "Finn Mattis",
          "affiliation": "GCDS",
          "affiliationURL": "https://www.gcds.net/"
        }
      ],
      "katex": {
        "delimiters": [{ "left": "$", "right": "$", "display": false }]
      }
    }
  </script>
</d-front-matter>

<d-title>
  <h1>A Mechanistic Investigation of Music Generation</h1>
</d-title>
<d-byline></d-byline>
<d-article>
  <p>
    Modern AI models such as Stable Diffusion and ChatGPT demonstrate remarkable
    and often surprising capabilities. Yet, their inner workings remain largely
    opaque. These systems are often described as "black boxes" as we can easily
    observe their inputs and outputs, but their inner workings are hidden and
    mysterious. As AI models are increasingly deployed across real-world
    applications, their black box nature is becoming increasingly untennable.
    The field of interptability aims to demistify these sytems and provide
    insight into their internal mechanisms.
  </p>
  <p>
    But how did this come to be? How did researchers create programs that they
    themselves didn't understand? To answer that, we have to go back.
  </p>
  <p>
    Despite its recent flood of attention, AI was largely dismissed as an
    unserious field for much of its existence. Since the advent of computers in
    the 1950s, ambitious programmers promsied we were on the cusp of building
    systems smarter than us. The loose term "AI" emerged to encompass programs
    that mimicked human intelligence in some way. But time and time again, those
    promises fell flat.
  </p>
  <p>
    The core challenge of AI is the rigidity of computers. Computer chips
    themselves can only perform a handful of simple operations: things like
    adding numbers, comparing values, and moving data between memory locations.
    Programs are constructed by chaining together millions—sometimes billions—of
    these atomic operations. But for a program to function correctly, every step
    must be painstakingly spelled out. The programmer has to antipcate every
    possible case and define, in exact terms, what the system should do in each
    one.
  </p>
  <p>
    From this perspective, the dream of artificial intelligence feels almost
    absurd. Intelligence, after all, is messy—it's intuitive, context-dependent,
    and often based on experience rather than explicit rules. We make decisions
    based on gut feelings, interpret language filled with ambiguity, and adapt
    to new situations without being told exactly what to do. How could a system
    so rigid, so mechanical, ever give rise to the complexitity and nuance of
    human thought?
  </p>
  <p>
    So while computers excelled within controlled domains, the goal of some sort
    of general intelligence felt like a pipe-dream. Machine triumphed over man
    in backgammom and chess, but man was content to have painting, poetry, and
    music safetly out of reach. As such, the field of AI lay dormant in the
    following decades. It drifted from the public imagination and grew
    increasingly disconnected from mainstream computer science.
  </p>
  <p>
    Still, some engineers envisioned machine intelligence radically differently.
    They pictured programs that could learn from examples instead of rely on
    human instruction. In 1957, Frank Rosenblatt unveiled the perceptron, a
    simple model rougly analogous to neurons in the brain. The system took in
    binary inputs with each input connected to the output by a corresponding
    "synapse" (often called a weight) that determined its influence on the final
    binary decision. Rossenblatt demonstrated how his machine could differntiate
    basic shapes on a grid, such as "T"s from "J"s, given the right weights.
    Additionally, Rosenblatt proposed a simple learning rule that allowed his
    model to "learn" its weights on its own through a handful of examples.
  </p>
  <p>
    Rossenblatt's rule worked as follows: for each example input, the
    corresponding weights are either increased or decreased by small constant
    ammount depending on the desired output. Over time, these small corrections
    would accumulate, gradually pushing the model toward the correct behavior.
    In the frenzy of post-WWII tech optimism, the discovery generated a lot of
    excitement. The New York Times proclaimed that Rosenblatt's perceptron would
    be able to "walk, talk, see, write, reproduce itself, and be conscious of
    its existence".
  </p>
  <p>
    In hindsight, Rossenblatt's approach seems like the obvious way forward.
    After all, isn't some kind of learning how the brain works? However,
    Rossenblatt's methods had major limitations. His simple perceptron model
    could only learn the most trivial tasks. For anything complicated, his rule
    would end up in an endless loop. To counter this, Rossenblatt proposed
    networks composed of multiple perceptrons, but he was unable to find a more
    general learning rule. Additionally, at the time, scientists had no real
    understanding of how learning worked in the brain,<d-footnote
      >Which we still don't</d-footnote
    >let alone how to replicate it in a machine. Even with all the challenges of
    writing programs by hand, they at least offered a clear path forward. You
    could follow the logic, fix mistakes, and know exactly what the system was
    doing-none of which was true for these early learning models. The idea was
    bold, but the technology was crude, and interest soon fizzled out.
  </p>
  <p>
    Still, a small group of dedicated researchers pushed Rossenblatt's work
    forward. The first real progress toward a more general learning rule came in
    1960, when Bernard Widrow and Marcian Hoff introduced a new approach.
    Instead of Rossenblatt's simple update rule, they used calculus to derive a
    more precise method for training a single perceptron-what become known as
    the Least Mean Squares (LMS) algorithm. This method closely resembles modern
    techniques, but it stopped short of providing a general learning rule. That
    breakthrough wouldn't come until 1986, when Backpropagation was first
    introduced. <d-footnote>kind of</d-footnote>.
  </p>
  <p>
    Backpropagation is very similar to the LMS algorithm. A key insight made in
    the time between LMS and Backpropagation was to allow perceptrons to take on
    a continuous range of values rather than just being on or off. This allows
    for the effect of earlier perceptrons on later neurons to be quantified with
    calculus. Additionally, the method's namesake forward-backward approach
    reuses intermediate results from the forward pass to efficiently compute
    weight updates during the backward pass. Still, many researchers were
    skeptical. It was widely believed that the method simply didn't work in
    practice.
  </p>
  <p>
    However, the success of ML in the 90s would show that backpropagation could
    in fact work. During this time, researchers developed systems for
    hisorically challenging problems like handwriting recognition and speech
    processing. While a major milestone in the field, these programs still
    didn't awe the public. The tasks still felt narrow and robotic-useful, but a
    far cry from human intelligence. While it was accepted that backpropagation
    could solve these simpler problems, it was still doubtful that these methods
    would allow for more general intelligence. Surely the brain's intelligence
    can't be mimicked through a simple update rule?
  </p>
  <p>
    That changed in 2012. A deep convolutional neural network called AlexNet
    blew past the competition in the ImageNet challenge, a high-profile
    benchmark for image-recognition. While other systems relied on human
    engineering and carefully tuned mathematical tricks, AlexNet was trained
    end-to-end using nothing more than backpropagation. And it didn't just
    win-it crushed the field. So what changed? Alexnet still used the same core
    ideas that researchers had know about since the 80s and 90s. The only
    difference was scale. Alexnet was orders of magnitude larger than previous
    networks.
  </p>
  <p>
    It's hard to understate what a watershed moment AlexNet was for AI. Once
    dismissed as unreliable, backpropagation had become not just accepted, but
    revered—almost mythologized. What kind of fantastical algorithms had it
    found that beat the competition so badly? What did backpropagation know that
    we didn't? These quesitons spurred the dawn of interptability efforts. Once
    the initial shock faded, another realization quickly set in: this was not
    the end. If a network this size could achieve results like that, what about
    a model 10x as large? 100x? A million times larger?
  </p>
  <p>
    The AI landscape since AlexNet has been pure chaos as researchers scramble
    to put together bigger and bigger models. In 2014, VGG demonstrated another
    giant leap in image-recognition. The next year, ResNet introduced skip
    connections allowing networks to go hundreds of layers deep without
    collapsing. Then in 2017, transformers brought the AI revolution to
    language. Models like BERT (2018), GPT-2 (2019), and GPT-3 (2022). In 2022,
    this wave reached the public with the release of ChatGPT.
  </p>
  <p>
    While there were earlier attempts to peek inside neural networks, the first
    real stab at gaining a deeper, mechanistic understanding came in 2020 with
    the launch of the Distill Circuits thread. Researchers didn't just ask what
    individual neurons responded to—they examined how neurons composed into
    larger circuits that performed meaningful functions. The thread found early
    success identifying components like curve detectors in vision models,
    sparking renewed interest in the possibility of truly understanding deep
    networks. But as language models began to dominate the landscape, much of
    the field's attention shifted toward them—driven in part by security
    concerns, model misuse, and their increasingly unpredictable behavior. These
    models presented their own unique challenges. In response, Anthropic
    launched the Transformer Circuits thread, a kind of spiritual successor to
    Distill, aimed at reverse-engineering the inner workings of language models
    layer by layer.
  </p>
  <p>
    While the large-scale deployment of language models has motivated serious
    efforts to understand them, other modalities—such as music—remain
    mechanistically under-studied. The goal of this paper is to apply some of
    these established interptability techniques to this new domain.
  </p>
  <h1>Setup</h1>
  <p>
    As some background for the paper, I'll assume familiarity with the basics of
    ML and transformer models. If these concepts are new, you can check at
    3Blue1Brown's excellent
    <a
      href="https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
      >video series</a
    >
    covering these topics.
  </p>
  <p>
    To begin, we need to select a suitable model for our investigation. Among
    open-source music generation models, Google's MusicLM and Meta's MusicGen
    are both transformer-based and represent the current state of the art. While
    their performance is broadly comparable, MusicGen holds a slight edge in
    quality and therefore will serve as the object of our study.
  </p>
  <p>
    There are some key differences between the modalities of text and sound. The
    most obvious is that text is discrete will sound is continuous.
  </p>
</d-article>

<d-appendix
  ><h3>Specific Details</h3>
  <p>
    Lorem ipsum dolor sit amet consectetur adipisicing elit. Distinctio nostrum
    rerum dolorum necessitatibus aliquid aperiam suscipit illum beatae nihil,
    consectetur unde accusamus, quasi, voluptatem at aspernatur obcaecati eos
    laboriosam porro? Sapiente reiciendis optio sequi repellendus minima!
    Provident labore excepturi maiores quisquam autem temporibus iure sed,
    dignissimos non voluptas blanditiis veniam laboriosam fugit incidunt quidem
    id eveniet delectus odio. Perferendis, iusto! Totam consectetur iusto
    consequatur nesciunt adipisci voluptatibus esse voluptatum molestias nobis.
    Harum maiores minima assumenda, incidunt numquam earum alias voluptatibus
    consequuntur dolorum dolor optio rem, repellendus fugit magni inventore ut!
    In laboriosam necessitatibus omnis accusantium fugiat? Eligendi ea libero
    beatae, doloremque eos esse sunt voluptas laudantium voluptates dolor omnis
    reiciendis, enim, distinctio minima illo necessitatibus et sed voluptatum
    labore eaque. Accusantium omnis delectus non tempore molestiae quis totam
    aut explicabo hic quisquam vitae esse, repellendus cum blanditiis? Velit,
    magnam quisquam laudantium autem sit delectus possimus harum magni,
    veritatis commodi totam? Dolorem maxime necessitatibus nostrum expedita,
    quas reiciendis similique ullam quo assumenda illo architecto reprehenderit
    numquam sint vel obcaecati adipisci, aspernatur libero. Ducimus corrupti
    distinctio error possimus optio a. Id, laudantium. Nostrum saepe, alias
    libero architecto consequatur ullam corporis. Tempora reprehenderit
    voluptatum cupiditate ullam ab explicabo nostrum ut id sequi, tempore
    pariatur quis similique enim voluptate quam alias ducimus, consequuntur
    libero. Accusamus dolore voluptatem dolorem quo vero dolor eius, cumque
    culpa voluptates est aspernatur officiis magni ea quibusdam doloremque totam
    ipsa fugiat earum perspiciatis consectetur laudantium eos harum? Soluta, ad
    labore. Harum eum illum quasi atque animi quidem a recusandae! Saepe
    eligendi nisi vitae doloribus qui minus delectus deserunt aliquid hic totam,
    natus maxime voluptatum suscipit corporis error facere ipsum. Voluptatum? Ab
    incidunt ut voluptates omnis tenetur rem culpa provident? Repudiandae
    corrupti velit animi cumque architecto minima expedita aperiam nesciunt
    minus asperiores alias, ab fugit blanditiis repellat inventore ut similique.
    Illum?
  </p>
</d-appendix>
<d-bibliography src="bibliography.bib"></d-bibliography>

<script type="text/bibliography">
  @article{gregor2015draw,
    title={DRAW: A recurrent neural network for image generation},
    author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
    journal={arXivreprint arXiv:1502.04623},
    year={2015},
    url={https://arxiv.org/pdf/1502.04623.pdf}
  }
</script>
